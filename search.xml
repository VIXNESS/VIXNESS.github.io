<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[PM2.5 é¢„æµ‹]]></title>
    <url>%2F2018%2F12%2F24%2FPM2-5%2F</url>
    <content type="text"><![CDATA[ä½¿ç”¨Linear Regression å¯¹PM2.5è¿›è¡Œé¢„æµ‹æ•°æ®é›† training data testing data: samples testing data: label Training data å’Œ Public testing data çš„ç»„ç»‡å½¢å¼: ä¸€å¤©ç”±18è¡Œç»„æˆ,ä¸€è¡Œä¸ºä¸€ä¸ªæŒ‡æ ‡,ä¸€å…±ç”±18ä¸ªæŒ‡æ ‡,ä»Žç¬¬4åˆ—å¼€å§‹è®°å½•æ¯ä¸ªæŒ‡æ ‡ä¸€å¤©å†…24å°æ—¶çš„å˜åŒ–æ•°å€¼,æ¯ä¸ªæœˆè¿žç»­è®°å½•å‰20å¤©ä½œä¸ºtraining set,åŽ10å¤©ä½œä¸ºtesting set,ä¸€å…±è®°å½•äº†240ä¸ªå°æ—¶ æ—¥æœŸ è§‚æµ‹ç«™ æŒ‡æ ‡ 0æ—¶ â€¦ 23æ—¶ day 1 xxx PM2.5 day 1 xxx PM10 day 1 xxx SO2 day 1 xxx â€¦ day 2 xxx PM2.5 day 2 xxx PM10 day 2 xxx SO2 day 2 xxx â€¦ æ•°æ®å¤„ç†å¿…è¦ç±»åº“1234567import osimport tensorflow as tffrom tensorflow import kerasimport csvimport sysimport numpy as npimport matplotlib.pyplot as plt è½½å…¥æ•°æ®12345678910111213141516data = []for i in range(18): data.append([]) # åˆå§‹åŒ–18åˆ—n_row = 0with open('train.csv','r',encoding = 'big5') as text: #csvç¼–ç æ˜¯big5 row = csv.reader(text, delimiter = ",") for r in row: if n_row != 0: for i in range(3,27): if r[i] != "NR": #NRä¸ºæœªé™é›¨,å¯¹å…¶è®¾ç½®ä¸ºé™é›¨é‡ data[(n_row - 1) % 18].append(float(r[i])) else: #è®¾æ–½0é™é›¨ä¸ºä¸€ä¸ªæŽ¥è¿‘0çš„å°é‡, #è‹¥è®¾ä¸º0,åŽç»­çš„æ¢¯åº¦è®¡ç®—ä¼šæœ‰é™¤0çš„é£Žé™© data[(n_row - 1) % 18].append(float(0.0001)) n_row += 1 é‡æ–°ç»„ç»‡æ•°æ® å°†ä¹‹å‰çš„æ•°æ®é‡æ–°ç»„ç»‡,å¯¹æ¯ä¸ªå°æ—¶è¿›è¡Œè¿žç»­æ‹¼æŽ¥ Features 0æ—¶ â€¦ 23æ—¶ 0æ—¶(æ¬¡æ—¥) â€¦ 23æ—¶ PM2.5 â€¦ .. PM 10 123456789101112131415161718x = [] # æ ·æœ¬çŸ©é˜µy = [] # å®žé™…çš„å€¼for i in range(12): # 12ä¸ªæœˆ for j in range(471): # æ¯è¾“å…¥9ä¸ªå°æ—¶çš„æ•°å€¼,é¢„æµ‹ç¬¬10ä¸ªå°æ—¶çš„PM2.5å€¼, # è¿™æ ·è¿žç»­çš„ã€Œ10ä¸ªå°æ—¶ã€æ¯ä¸ªæœˆæœ‰471ä¸ª x.append([]) # for w in range(18): # éåŽ†18ä¸ªç‰¹å¾ for t in range(9): # éåŽ†å‰9ä¸ªå°æ—¶ x[471 * i + j].append(data[w][480 * i + j + t]) # å°†ç¬¬10ä¸ªå°æ—¶çš„å€¼ä½œä¸ºå®žé™…çš„PM2.5çš„å€¼ y.append(data[9][480 * i + j + 9])x = np.array(x)y = np.array(y)#åœ¨ç¬¬ä¸€åˆ—æ·»ä¸Šä¸€æ¡å…¨ä¸º1çš„åˆ—ä½œä¸ºbiasx = np.concatenate((np.ones((x.shape[0],1)),x),axis = 1) w = np.zeros(x.shape[1]) #weight è®­ç»ƒå®šä¹‰loss function ä½¿ç”¨ error square123456def lossFunction(target,weight,samples): M = target - np.dot(weight,samples.T) loss = 0 for m in M: loss += m**2 return loss Gradient Descent ä½¿ç”¨Adagra å¯¹learning rateè¿›è¡ŒæŽ§åˆ¶ 12345678910111213lr = 8 #learning rate è®¾ç½®pre_grad = np.ones(x.shape[1])# æ¯ä¸ªç‰¹å¾æœ‰ç‹¬ç«‹çš„learning ratefor r in range(10000): temp_loss = 0 for m in range(36): for s in range(156): L = np.dot(w,x[157 * m + s].T) - y[157 * m + s] grad = np.dot(x[157 * m + s].T,L)*(2) pre_grad += grad**2 ada = np.sqrt(pre_grad) w = w - lr * grad/ada temp_loss += abs(np.dot(w,x[157 * m + 156].T) - y[157 * m + 156]) print("%.2f" % (r * 100 / 10000),'% loss:',"%.4f" % (temp_loss / 36)) ä¿å­˜ weights1np.save('model.npy',w) æµ‹è¯• åŠ è½½æµ‹è¯•ç‰¹å¾æ•°æ®é›†(ç•¥) åŠ è½½label 123456789y = []rr = 0with open('ans.csv','r',encoding = 'big5') as ans: row = csv.reader(ans,delimiter = ',') for r in row: if rr != 0: y.append(float(r[1])) rr += 1y = np.array(y) åŠ è½½weights 1w = np.load('model.npy') æµ‹è¯• 123456789101112t = np.dot(x,w)L = t - yloss = []sum = 0for l in L: loss.append(abs(l)) sum += abs(l)print(sum / len(L))plt.plot(y,color = "red",label = 'target')plt.plot(t,color = "blue",label = 'hypothesis')plt.ylabel('pm 2.5')plt.show() ç»“æžœ PM2.5 è¯¯å·® 14.427å‚æ•°å¤ªå¤š,è¿‡æ‹Ÿåˆäº† æ˜¯æ²¡æœ‰è®­ç»ƒå¥½,å¡åœ¨äº†æŸä¸ªåœ°æ–¹äº†,trainingæ—¶å€™çš„lossä¹Ÿå¾ˆé«˜ //ä¹‹åŽå†ç»™å‡ºtrainingæ—¶å€™çš„loss,å¤ªæ…¢äº†,çœŸÂ·è·‘ä¸€ä¸‡ä¸‹ å†ä¼˜åŒ– åªå–18ä¸ªç‰¹å¾ä¸­çš„NMHCã€NO2ã€O3ã€PM10ã€PM2.5 PM2.5 è¯¯å·® 8.987ä¸€ä¸ªä¸é”™çš„å¼€å¤´,ç»§ç»­ä¼˜åŒ– åªè€ƒè™‘PM 10å’ŒPM 2.5 PM2.5 è¯¯å·® 6.281 è‹¥åœ¨åˆ å‡ç‰¹å¾å‘¢?åªè€ƒè™‘ PM2.5 PM2.5 è¯¯å·® 5.406æˆ‘æœäº†,ä¹‹å‰åšçš„æ—¶å€™æ˜¯ä¼šunderfittingå¯¼è‡´è¯¯å·®åˆ°7.4çš„,è¿™å›žå€’å¥½æ›´åŠ ä½Žäº† ä½¿ç”¨Deep Learning å¯¹PM2.5è¿›è¡Œé¢„æµ‹]]></content>
      <categories>
        <category>machine learning</category>
      </categories>
      <tags>
        <tag>machine learing</tag>
        <tag>linear regression</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2018%2F12%2F23%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Hello World! æˆ‘å›žæ¥å•¦~â•â•â•â•å¼€å§‹å†™ä½œ,æ›´æ–°blogå•¦ ðŸŽ‰ðŸŽ‰ðŸŽ‰ðŸŽ‰]]></content>
      <categories>
        <category>life</category>
      </categories>
      <tags>
        <tag>life</tag>
      </tags>
  </entry>
</search>
