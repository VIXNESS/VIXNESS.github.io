<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[PM2.5 预测]]></title>
    <url>%2F2018%2F12%2F24%2FPM2-5%2F</url>
    <content type="text"><![CDATA[使用Linear Regression 对PM2.5进行预测数据集 training data testing data: samples testing data: label Training data 和 Public testing data 的组织形式: 一天由18行组成,一行为一个指标,一共由18个指标,从第4列开始记录每个指标一天内24小时的变化数值,每个月连续记录前20天作为training set,后10天作为testing set,一共记录了240个小时 日期 观测站 指标 0时 … 23时 day 1 xxx PM2.5 day 1 xxx PM10 day 1 xxx SO2 day 1 xxx … day 2 xxx PM2.5 day 2 xxx PM10 day 2 xxx SO2 day 2 xxx … 数据处理必要类库1234567import osimport tensorflow as tffrom tensorflow import kerasimport csvimport sysimport numpy as npimport matplotlib.pyplot as plt 载入数据12345678910111213141516data = []for i in range(18): data.append([]) # 初始化18列n_row = 0with open('train.csv','r',encoding = 'big5') as text: #csv编码是big5 row = csv.reader(text, delimiter = ",") for r in row: if n_row != 0: for i in range(3,27): if r[i] != "NR": #NR为未降雨,对其设置为降雨量 data[(n_row - 1) % 18].append(float(r[i])) else: #设施0降雨为一个接近0的小量, #若设为0,后续的梯度计算会有除0的风险 data[(n_row - 1) % 18].append(float(0.0001)) n_row += 1 重新组织数据 将之前的数据重新组织,对每个小时进行连续拼接 Features 0时 … 23时 0时(次日) … 23时 PM2.5 … .. PM 10 123456789101112131415161718x = [] # 样本矩阵y = [] # 实际的值for i in range(12): # 12个月 for j in range(471): # 每输入9个小时的数值,预测第10个小时的PM2.5值, # 这样连续的「10个小时」每个月有471个 x.append([]) # for w in range(18): # 遍历18个特征 for t in range(9): # 遍历前9个小时 x[471 * i + j].append(data[w][480 * i + j + t]) # 将第10个小时的值作为实际的PM2.5的值 y.append(data[9][480 * i + j + 9])x = np.array(x)y = np.array(y)#在第一列添上一条全为1的列作为biasx = np.concatenate((np.ones((x.shape[0],1)),x),axis = 1) w = np.zeros(x.shape[1]) #weight 训练定义loss function 使用 error square123456def lossFunction(target,weight,samples): M = target - np.dot(weight,samples.T) loss = 0 for m in M: loss += m**2 return loss Gradient Descent 使用Adagra 对learning rate进行控制 12345678910111213lr = 8 #learning rate 设置pre_grad = np.ones(x.shape[1])# 每个特征有独立的learning ratefor r in range(10000): temp_loss = 0 for m in range(36): for s in range(156): L = np.dot(w,x[157 * m + s].T) - y[157 * m + s] grad = np.dot(x[157 * m + s].T,L)*(2) pre_grad += grad**2 ada = np.sqrt(pre_grad) w = w - lr * grad/ada temp_loss += abs(np.dot(w,x[157 * m + 156].T) - y[157 * m + 156]) print("%.2f" % (r * 100 / 10000),'% loss:',"%.4f" % (temp_loss / 36)) 保存 weights1np.save('model.npy',w) 测试 加载测试特征数据集(略) 加载label 123456789y = []rr = 0with open('ans.csv','r',encoding = 'big5') as ans: row = csv.reader(ans,delimiter = ',') for r in row: if rr != 0: y.append(float(r[1])) rr += 1y = np.array(y) 加载weights 1w = np.load('model.npy') 测试 123456789101112t = np.dot(x,w)L = t - yloss = []sum = 0for l in L: loss.append(abs(l)) sum += abs(l)print(sum / len(L))plt.plot(y,color = "red",label = 'target')plt.plot(t,color = "blue",label = 'hypothesis')plt.ylabel('pm 2.5')plt.show() 结果 PM2.5 误差 14.427参数太多,过拟合了 是没有训练好,卡在了某个地方了,training时候的loss也很高 //之后再给出training时候的loss,太慢了,真·跑一万下 再优化 只取18个特征中的NMHC、NO2、O3、PM10、PM2.5 PM2.5 误差 8.987一个不错的开头,继续优化 只考虑PM 10和PM 2.5 PM2.5 误差 6.281 若在删减特征呢?只考虑 PM2.5 PM2.5 误差 5.406我服了,之前做的时候是会underfitting导致误差到7.4的,这回倒好更加低了 使用Deep Learning 对PM2.5进行预测]]></content>
      <categories>
        <category>machine learning</category>
      </categories>
      <tags>
        <tag>machine learing</tag>
        <tag>linear regression</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2018%2F12%2F23%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Hello World! 我回来啦~❕❕❕❕开始写作,更新blog啦 🎉🎉🎉🎉]]></content>
      <categories>
        <category>life</category>
      </categories>
      <tags>
        <tag>life</tag>
      </tags>
  </entry>
</search>
